{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0HCWrSSqBWc",
        "outputId": "f7a1fbf8-1944-4b2c-88d2-6d27cc0572f3"
      },
      "outputs": [],
      "source": [
        "# prompt: export pretrained keras mobilenet model to tflite, quantize to INT8\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# download the weights from\n",
        "# https://github.com/NavodPeiris/MobileNet_96x96_greyscale_weights\n",
        "!wget https://raw.githubusercontent.com/NavodPeiris/MobileNet_96x96_greyscale_weights/main/mobilenetV1_0.1_96x96_greyscale_weights.h5\n",
        "!wget https://raw.githubusercontent.com/NavodPeiris/MobileNet_96x96_greyscale_weights/main/mobilenetV1_0.2_96x96_greyscale_weights.h5\n",
        "!wget https://raw.githubusercontent.com/NavodPeiris/MobileNet_96x96_greyscale_weights/main/mobilenetV1_0.25_96x96_greyscale_weights.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uzAwbhdvwLE",
        "outputId": "0da4988b-2264-40b4-9eac-a463bfa7edf7"
      },
      "outputs": [],
      "source": [
        "# download cat vs. dog dataset\n",
        "# from https://www.kaggle.com/datasets/anthonytherrien/dog-vs-cat\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Kaggle\"\n",
        "!kaggle datasets download -d anthonytherrien/dog-vs-cat\n",
        "!unzip -q dog-vs-cat.zip -d .\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCeKspj4wkiN",
        "outputId": "cd940d02-19c2-44b6-829b-a7f314c30c3a"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 96\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "COLOR_MODE = \"grayscale\"\n",
        "\n",
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\"animal\",\n",
        "                                                             shuffle = True,\n",
        "                                                             image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                                              color_mode = COLOR_MODE,\n",
        "                                                              batch_size = BATCH_SIZE,\n",
        "                                                              label_mode = \"categorical\"\n",
        "                                                             )\n",
        "def get_data_splitting_tf(dataset,\n",
        "                      train_split = 0.7,\n",
        "                      test_split = 0.15,\n",
        "                      val_split = 0.15,\n",
        "                      shuffle = True, # data will be shuffle show that no particular image in sellected more than once durring the splitting\n",
        "                      shuffle_size = 100000 #\n",
        "                      ):\n",
        "\n",
        "\n",
        "    data_size = len(dataset)\n",
        "    if shuffle:\n",
        "\n",
        "        dataset = dataset.shuffle(shuffle_size, seed = 42)\n",
        "    train_size = int(train_split * data_size)\n",
        "\n",
        "    test_size = int(test_split * data_size)\n",
        "\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    test_dataset = dataset.skip(train_size).take(test_size) # the test data will skip the data in the train dataset\n",
        "\n",
        "    val_dataset = dataset.skip(train_size).skip(test_size) # this will also skip all the dataset that has already been selected by the test and train size\n",
        "\n",
        "    return train_dataset, test_dataset, val_dataset\n",
        "\n",
        "train_dataset , test_dataset , val_dataset = get_data_splitting_tf(dataset)\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().shuffle(1000).prefetch(buffer_size =  tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "rescale_and_resize = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1.0/255)\n",
        "]) # Rescale and resizing the data\n",
        "\n",
        "# Data augmentation is done toe to introduce the data to different orrientations and also increase the size of the dataset\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"Horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.3)\n",
        "    ], name=\"data_augmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HvoTm-_AB1rM",
        "outputId": "eacb4403-6df3-406a-d9b3-8ddc41aac8f1"
      },
      "outputs": [],
      "source": [
        "class_names = dataset.class_names\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (15, 15))\n",
        "\n",
        "for image_batch, label_batch in dataset.take(1):\n",
        "    for j in range(20): # Showing 20 images from among the dadtaset in the two classes\n",
        "        ax = plt.subplot(4,5, j+1)\n",
        "        plt.imshow(image_batch[j].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[label_batch[j].numpy().argmax()])\n",
        "\n",
        "        plt.axis(False) # do not show axis for the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B8gbG3Lst_gr",
        "outputId": "91b29c25-3f38-49b0-e58e-4ed3ed241eee"
      },
      "outputs": [],
      "source": [
        "# clear keras session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_tensor = tf.keras.layers.Input(shape=(96, 96, 1))\n",
        "aug = data_augmentation(input_tensor)\n",
        "\n",
        "mobilenet_model = tf.keras.applications.MobileNet(\n",
        "    input_shape=(96, 96, 1),\n",
        "    input_tensor=aug,\n",
        "    pooling=\"avg\",\n",
        "    alpha=0.1,   # 0.25, 0.2, 0.1\n",
        "    weights=\"mobilenetV1_0.1_96x96_greyscale_weights.h5\", # 0.25, 0.2, 0.1\n",
        "    include_top=False\n",
        "    )\n",
        "\n",
        "mobilenet_model.trainable = False\n",
        "\n",
        "mobilenet_output = mobilenet_model.output\n",
        "\n",
        "# classification layer\n",
        "classification_layer = tf.keras.layers.Dense(2, activation='softmax')(mobilenet_output)\n",
        "\n",
        "model = tf.keras.Model(inputs=mobilenet_model.input, outputs=classification_layer)\n",
        "\n",
        "print(\"Compiling model...\")\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_k1a-dW_lZM",
        "outputId": "36d81940-efeb-4055-bfeb-8debec60bb99"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "                   train_dataset,\n",
        "                   epochs = EPOCHS,\n",
        "                   batch_size = BATCH_SIZE,\n",
        "                   verbose = 1,\n",
        "                   validation_data = val_dataset\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRfH_JoB_mXU",
        "outputId": "dae31d87-be4c-4e4c-b16b-2ff36b4c0dd4"
      },
      "outputs": [],
      "source": [
        "def representative_data_gen():\n",
        "  for image_batch, label_batch in dataset.take(1):\n",
        "    yield [image_batch]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# Set the input and output tensors to int8 (APIs added in r2.3)\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model_quant = converter.convert()\n",
        "# Save the quantized model\n",
        "with open('model_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_model_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "8pDYDPgEF0Fr",
        "outputId": "bf210e7e-7635-4cac-8578-0d27038589b2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Helper function to run inference on a TFLite model\n",
        "def run_tflite_model(tflite_file, test_images):\n",
        "\n",
        "  # Initialize the interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  predictions = np.zeros((len(test_images),), dtype=int)\n",
        "  for i, test_image in enumerate(test_images):\n",
        "\n",
        "    # Check if the input type is quantized, then rescale input data to uint8\n",
        "    if input_details['dtype'] == np.int8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "    predictions[i] = output.argmax()\n",
        "\n",
        "  return predictions\n",
        "\n",
        "# Change this to test a different image\n",
        "test_image_index = np.random.randint(0, BATCH_SIZE)\n",
        "\n",
        "## Helper function to test the models on one image\n",
        "def test_model(tflite_file, test_image_index):\n",
        "\n",
        "  # take one image from test dataset\n",
        "  test_data = list(test_dataset.take(2).as_numpy_iterator())[0]\n",
        "  test_image = test_data[0][test_image_index]\n",
        "  test_label = test_data[1][test_image_index]\n",
        "  predictions = run_tflite_model(tflite_file, [test_image])\n",
        "  plt.imshow(test_image)\n",
        "  template = \" Model \\n True:{true}, Predicted:{predict}\"\n",
        "  _ = plt.title(template.format(true = str(test_label.argmax()), predict=str(predictions[0])))\n",
        "  plt.grid(False)\n",
        "\n",
        "test_model('model_quant.tflite', test_image_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JJ8shAfUVWH",
        "outputId": "681f3927-6ecb-4283-996b-a1d6445cb878"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(tflite_file):\n",
        "\n",
        "  test_data = list(test_dataset.take(1).as_numpy_iterator())[0]\n",
        "  test_images = test_data[0]\n",
        "  test_labels = test_data[1].argmax(axis=1)\n",
        "  predictions = run_tflite_model(tflite_file, test_images)\n",
        "\n",
        "  accuracy = (np.sum(test_labels==predictions) * 100) / len(test_images)\n",
        "\n",
        "  print('model accuracy is %.4f%% (Number of test samples=%d)' % (accuracy, len(test_images)))\n",
        "\n",
        "evaluate_model('model_quant.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da4c4UD02mcV"
      },
      "outputs": [],
      "source": [
        "!xxd -i  model_quant.tflite > model.h"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
